{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BitM - ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical Path\n",
    "hist_path = 'data/hist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Path \n",
    "daily_path = 'data/daily/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    files = os.listdir(path)\n",
    "    # Filter only CSV files\n",
    "    return [file for file in files if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_in_dir(path, cols, fn):\n",
    "    dfTmp = []\n",
    "    files = get_files(path)\n",
    "    for file in files:\n",
    "        filepath = os.path.join(path, file)\n",
    "        df = pd.read_csv(filepath, sep=';', names=cols, header=1, usecols=range(len(cols)))\n",
    "        dfTmp.append(fn(file, df))\n",
    "    \n",
    "    return pd.concat(dfTmp, ignore_index=True) if files else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Fecha', 'Nemotécnico', 'Precio cierre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = lambda df : df.rename(columns={'Fecha': 'Date', 'Precio cierre': 'Close', 'Nemotécnico':'Stock'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_close = lambda df : df['Close'].astype(str).str.replace(',', '').replace('-', '0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast date column\n",
    "cast_date = lambda df : pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hist(file, df):\n",
    "    print(f'processing file {file}')\n",
    "    df = rename_cols(df)    \n",
    "    df['Close'] = cast_close(df)\n",
    "    df['Date'] = cast_date(df)\n",
    "    df.insert(1, 'src', 'hist')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file BCOLOMBIA_20240613_055318.csv\n",
      "processing file BOGOTA_20240613_114646.csv\n",
      "processing file CELSIA_20240614_101420.csv\n",
      "processing file CEMARGOS_20240613_114831.csv\n",
      "processing file CORFICOLCF_20240614_101233.csv\n",
      "processing file ECOPETROL_20240702_101105.csv\n",
      "processing file GEB_20240613_055444.csv\n",
      "processing file GRUBOLIVAR_20240614_101320.csv\n",
      "processing file GRUPOARGOS_20240613_114334.csv\n",
      "processing file GRUPOSURA_20240613_114143.csv\n",
      "processing file ISA_20240613_055521.csv\n",
      "processing file NUTRESA_20240613_115147.csv\n",
      "processing file PFAVAL_20240613_114405.csv\n",
      "processing file PFBCOLOM_20240613_055405.csv\n",
      "processing file PFCORFICOL_20240614_101155.csv\n",
      "processing file PFDAVVNDA_20240613_114741.csv\n",
      "processing file PFGRUPOARG_20240613_114232.csv\n",
      "processing file PFGRUPSURA_20240613_055607.csv\n",
      "processing file PROMIGAS_20240614_101116.csv\n"
     ]
    }
   ],
   "source": [
    "dfHist = process_files_in_dir(hist_path, column_names, process_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Nemotécnico', 'Último precio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = lambda df : df.rename(columns={'Último precio': 'Close', 'Nemotécnico':'Stock'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_close_daily = lambda df : df['Close'].astype(str).str.replace(',', '.').replace('-', '0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(file_name):\n",
    "    \n",
    "    # Regular expression pattern\n",
    "    pattern = r'RVLocal_(\\d{4})(\\d{2})(\\d{2})\\.csv'\n",
    "    \n",
    "    # Search for the pattern in the string\n",
    "    match = re.search(pattern, file_name)\n",
    "    \n",
    "    # Extract the matched groups\n",
    "    if match:\n",
    "        year = match.group(1)\n",
    "        month = match.group(2)\n",
    "        day = match.group(3)\n",
    "        return f\"{year}-{month}-{day}\"\n",
    "\n",
    "    return '1900-01-01'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_daily(filename, df):\n",
    "\n",
    "    df = rename_cols(df)\n",
    "    df['Close'] = cast_close_daily(df)\n",
    "    # Insert the new column at the beginning\n",
    "    df.insert(0, 'Date', add_date(filename))\n",
    "    df['Date'] = cast_date(df)\n",
    "    df.insert(1, 'src', 'daily')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDaily = process_files_in_dir(daily_path, column_names, process_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStockTemp = pd.concat([dfHist, dfDaily], ignore_index=True) \\\n",
    "                .sort_values(by=['Stock', 'Date', 'src'], ascending=[True, True, False]) \\\n",
    "                .drop_duplicates(subset=['Stock', 'Date'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>src</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>daily</td>\n",
       "      <td>TERPEL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>daily</td>\n",
       "      <td>TERPEL</td>\n",
       "      <td>9010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>daily</td>\n",
       "      <td>TERPEL</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>daily</td>\n",
       "      <td>TERPEL</td>\n",
       "      <td>9010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>daily</td>\n",
       "      <td>VALSIMESA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    src      Stock   Close\n",
       "2431 2024-06-26  daily     TERPEL     0.0\n",
       "2455 2024-06-27  daily     TERPEL  9010.0\n",
       "2498 2024-06-28  daily     TERPEL  9000.0\n",
       "2525 2024-07-02  daily     TERPEL  9010.0\n",
       "2368 2024-06-24  daily  VALSIMESA     0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfStockTemp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
